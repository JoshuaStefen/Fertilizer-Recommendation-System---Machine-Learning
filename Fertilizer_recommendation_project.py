# -*- coding: utf-8 -*-
"""Test final mini project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M7vn-CjqxrxVLfNZ8RTiCXFSbkaDd9Iq
"""

!pip install pytorch_tabnet

!pip install seaborn

# Import necessary libraries
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report

# Read the dataset
dataset = pd.read_csv('Crop_and_fertilizer_dataset.csv')

dataset.describe()

# Basic information about the dataset
print(dataset.info())

# Statistical summary of the dataset
print(dataset.describe())

plt.figure(figsize=(40,40))
sns.countplot(x='Fertilizer', data = dataset)
plt.show()

# Setting aesthetics for better readability of plots
sns.set(style="whitegrid")
plt.rcParams['figure.figsize'] = [10, 8]

# Plotting histograms for each feature
dataset.hist(bins=15, figsize=(15, 10))
plt.suptitle('Distribution of Features')
plt.show()

# Box plots for each feature
dataset.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=(15, 10))
plt.suptitle('Box Plot for Each Feature')
plt.show()

corr = dataset.drop(columns=['District_Name', 'Soil_color', 'pH', 'Rainfall', 'Temperature', 'Crop', 'Link','Fertilizer']).corr()
corr

corr['Nitrogen'].plot(kind='line', figsize=(8, 4), title='NPK Relationship')
plt.gca().spines[['top', 'right']].set_visible(False)

sns.heatmap(corr, annot = True, cbar = True, cmap = 'coolwarm')

# Plotting the distribution graphs of the variables
plt.figure(figsize=(15, 5))

# Enumerating through each numeric column for distribution plot
for i, column in enumerate(['Nitrogen', 'Potassium', 'Phosphorus'], start=1):
    plt.subplot(1, 3, i)
    sns.histplot(dataset[column], bins=20, kde=True)
    plt.title(f'Distribution of {column}')

plt.tight_layout()
plt.show()

# Removing multiple columns from the DataFrame
numeric_data = dataset.drop(['District_Name', 'Soil_color', 'pH', 'Rainfall', 'Temperature', 'Link', 'Fertilizer'], axis=1)

# Handling null values
dataset.dropna(inplace=True)

# Perform label encoding for the target variable
label_encoder = LabelEncoder()
dataset['Fertilizer'] = label_encoder.fit_transform(dataset['Fertilizer'])

#dataset.head()

# Apply label encoding to the 'Crop' column
dataset['Crop'] = label_encoder.fit_transform(dataset['Crop'])

#dataset.head()

# Split the dataset into features (X) and target variable (y)
X = dataset.drop(columns=['District_Name', 'Soil_color', 'pH', 'Rainfall', 'Temperature', 'Link'])
#X = dataset[['Nitrogen', 'Phosphorus', 'Potassium', 'Crop']]
y = dataset['Fertilizer']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#print(X_train.columns)
#X_train.info()

#dataset.head()

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled[0]

# TabNet Classifier with hyperparameter tuning
clf = TabNetClassifier(n_d=64, n_a=64, n_steps=5, gamma=1.5, lambda_sparse=0.0001, optimizer_params=dict(lr=0.01, weight_decay=1e-5))

# Train the classifier using the scaled training data
clf.fit(
    X_train=X_train_scaled,y_train=y_train,eval_set=[(X_train_scaled, y_train), (X_test_scaled, y_test)],eval_name=['train', 'test'],eval_metric=['accuracy'],max_epochs=14,patience=10)

#dataset.head()

# Evaluate the classifier
evals_result = clf.history
print("Best validation accuracy:", max(evals_result['test_accuracy']))

# Generate predictions
y_pred = clf.predict(X_test_scaled)

# Print precision, recall, and F1-score
print(classification_report(y_test, y_pred))

# Plotting a single bar graph for accuracy, recall, precision, and F1-score
report_dict = classification_report(y_test, y_pred, output_dict=True)
metrics = ['accuracy', 'recall', 'precision', 'f1-score']
scores = [report_dict['accuracy'], report_dict['macro avg']['recall'], report_dict['macro avg']['precision'], report_dict['macro avg']['f1-score']]

plt.figure(figsize=(10, 6))
plt.bar(metrics, scores, color=['blue', 'orange', 'green', 'red'])
plt.title('Performance Metrics')
plt.xlabel('Metrics')
plt.ylabel('Scores')
plt.show()

#for item in dir(clf.history):
 #   print(item)

#dataset.head()

#print(dataset)

#feature_names = dataset.columns.tolist()
#for feature in feature_names:
 #   print(feature)

import ipywidgets as widgets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.ensemble import RandomForestClassifier

# Create combo box for District_name
district_widget = widgets.Combobox(
    options=tuple(dataset['District_Name'].unique()),
    description='District:',
    placeholder='Select district',
    ensure_option=True
)

# Create an empty soil color widget initially
soil_color_widget = widgets.Combobox(
    description='Soil Color:',
    placeholder='Select soil color',
    ensure_option=True
)

nitrogen_widget = widgets.Combobox(
    description='Nitrogen:',
    placeholder='Select nitrogen value',
    ensure_option=True
)

phosphorus_widget = widgets.Combobox(
    description='Phosphorus:',
    placeholder='Select phosphorus value',
    ensure_option=True
)

potassium_widget = widgets.Combobox(
    description='Potassium:',
    placeholder='Select potassium value',
    ensure_option=True
)

ph_widget = widgets.Combobox(
    description='pH:',
    placeholder='Select pH value',
    ensure_option=True
)

rainfall_widget = widgets.Combobox(
    description='Rainfall:',
    placeholder='Select rainfall value',
    ensure_option=True
)

temperature_widget = widgets.Combobox(
    description='Temperature:',
    placeholder='Select temperature value',
    ensure_option=True
)

recommend_widget = widgets.Output()


# Define the observer function to update soil color options
def update_soil_color_options(change):
    district = change.new
    if district:
        soil_colors = dataset[dataset['District_Name'] == district]['Soil_color'].unique()
        soil_color_widget.options = tuple(soil_colors)
    else:
        soil_color_widget.options = ()

# Define the observer function to update nitrogen options
def update_nitrogen_options(change):
    district = district_widget.value
    soil_color = soil_color_widget.value
    if district and soil_color:
        nitrogen_values = dataset[(dataset['District_Name'] == district) & (dataset['Soil_color'] == soil_color)]['Nitrogen'].unique()
        nitrogen_values = [str(value) for value in nitrogen_values]  # Convert to Unicode strings
        nitrogen_widget.options = tuple(nitrogen_values)
    else:
        nitrogen_widget.options = ()

def update_phosphorus_options(change):
    district = district_widget.value
    soil_color = soil_color_widget.value
    if district and soil_color:
        phosphorus_values = dataset[(dataset['District_Name'] == district) & (dataset['Soil_color'] == soil_color)]['Phosphorus'].unique()
        phosphorus_values = [str(value) for value in phosphorus_values]  # Convert to Unicode strings
        phosphorus_widget.options = tuple(phosphorus_values)
    else:
        phosphorus_widget.options = ()

def update_potassium_options(change):
    district = district_widget.value
    soil_color = soil_color_widget.value
    if district and soil_color:
        potassium_values = dataset[(dataset['District_Name'] == district) & (dataset['Soil_color'] == soil_color)]['Potassium'].unique()
        potassium_values = [str(value) for value in potassium_values]  # Convert to Unicode strings
        potassium_widget.options = tuple(potassium_values)
    else:
        potassium_widget.options = ()

def update_ph_options(change):
    district = district_widget.value
    soil_color = soil_color_widget.value
    if district and soil_color:
        ph_values = dataset[(dataset['District_Name'] == district) & (dataset['Soil_color'] == soil_color)]['pH'].unique()
        ph_values = [str(value) for value in ph_values]  # Convert to Unicode strings
        ph_widget.options = tuple(ph_values)
    else:
        ph_widget.options = ()

def update_rainfall_options(change):
    district = district_widget.value
    soil_color = soil_color_widget.value
    if district and soil_color:
        rainfall_values = dataset[(dataset['District_Name'] == district) & (dataset['Soil_color'] == soil_color)]['Rainfall'].unique()
        rainfall_values = [str(value) for value in rainfall_values]  # Convert to Unicode strings
        rainfall_widget.options = tuple(rainfall_values)
    else:
        rainfall_widget.options = ()

def update_temperature_options(change):
    district = district_widget.value
    soil_color = soil_color_widget.value
    if district and soil_color:
        temperature_values = dataset[(dataset['District_Name'] == district) & (dataset['Soil_color'] == soil_color)]['Temperature'].unique()
        temperature_values = [str(value) for value in temperature_values]  # Convert to Unicode strings
        temperature_widget.options = tuple(temperature_values)
    else:
        temperature_widget.options = ()

# Train the model
def train_model(change):
    # Get the selected values from the combo boxes
    district = district_widget.value
    soil_color = soil_color_widget.value
    nitrogen = float(nitrogen_widget.value)
    phosphorus = float(phosphorus_widget.value)
    potassium = float(potassium_widget.value)
    pH = float(ph_widget.value)
    rainfall = float(rainfall_widget.value)
    temperature = float(temperature_widget.value)


    input_data = pd.DataFrame(
        [[nitrogen, phosphorus, potassium, pH, rainfall, temperature, district, soil_color]],
        columns=['Nitrogen', 'Phosphorus', 'Potassium', 'pH', 'Rainfall', 'Temperature', 'District_Name', 'Soil_color']
    )

    # Perform one-hot encoding for District_Name and Soil_color columns
    encoder = OneHotEncoder(handle_unknown='ignore')
    X_encoded = encoder.fit_transform(dataset[['District_Name', 'Soil_color']])
    input_data_encoded = encoder.transform(input_data[['District_Name', 'Soil_color']])

    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_encoded, dataset['Crop'], test_size=0.2, random_state=42)

    # Train the random forest model
    model_crop = RandomForestClassifier(n_estimators=100, random_state=42)
    model_crop.fit(X_train, y_train)

    # Make predictions
    predicted_crop = model_crop.predict(input_data_encoded)

    # Find the fertilizer associated with the recommended crop
    recommended_fertilizer = dataset[dataset['Crop'] == predicted_crop[0]]['Fertilizer'].values[0]
    # Find the corresponding link for the predicted crop and fertilizer
    #link = dataset[(dataset['Crop'] == predicted_crop.iloc[0]) & (dataset['Fertilizer'] == recommended_fertilizer)]['Link'].values[0]
    link = dataset[(dataset['Crop'] == pd.Series(predicted_crop)[0]) & (dataset['Fertilizer'] == recommended_fertilizer)]['Link'].values[0]
    with recommend_widget:
        recommend_widget.clear_output()
        print("Recommended Crop:", predicted_crop[0])
        print("Recommended Fertilizer:", recommended_fertilizer)
        print("Link:", link)

# Define the observer function to update soil color options
district_widget.observe(update_soil_color_options, names='value')
district_widget.observe(update_nitrogen_options, names='value')
soil_color_widget.observe(update_nitrogen_options, names='value')


district_widget.observe(update_phosphorus_options, names='value')
soil_color_widget.observe(update_phosphorus_options, names='value')

district_widget.observe(update_potassium_options, names='value')
soil_color_widget.observe(update_potassium_options, names='value')

district_widget.observe(update_ph_options, names='value')
soil_color_widget.observe(update_ph_options, names='value')

district_widget.observe(update_rainfall_options, names='value')
soil_color_widget.observe(update_rainfall_options, names='value')

district_widget.observe(update_temperature_options, names='value')
soil_color_widget.observe(update_temperature_options, names='value')



# Create the button widget
button = widgets.Button(description='Train Model')
# Add the train_model function as an observer to the 'on_click' event of the button
button.on_click(train_model)

# Display the widgets
widgets.VBox([district_widget, soil_color_widget, nitrogen_widget,phosphorus_widget,potassium_widget,ph_widget,rainfall_widget,temperature_widget,button,recommend_widget])

# Reverse Label Encoding for Crop and Fertilizer
predicted_crop = label_encoder.inverse_transform(predicted_crop_encoded)
predicted_fertilizer = label_encoder.inverse_transform(predicted_fertilizer_encoded)

# Find the fertilizer associated with the recommended crop
recommended_fertilizer = predicted_fertilizer[0]

# Find the corresponding link for the predicted crop and fertilizer
link = dataset[(dataset['Crop'] == predicted_crop[0]) & (dataset['Fertilizer'] == recommended_fertilizer)]['Link'].values[0]

with recommend_widget:
    recommend_widget.clear_output()
    print("Recommended Crop:", predicted_crop[0])
    print("Recommended Fertilizer:", recommended_fertilizer)
    print("Link:", link)